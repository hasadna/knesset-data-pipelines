{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example flow for processing and aggregating stats about committee meeting attendees and protocol parts\n",
    "\n",
    "See the [DataFlows documentation](https://github.com/datahq/dataflows) for more details regarding the Flow object and processing functions.\n",
    "\n",
    "Feel free to modify and commit changes which demonstrate additional functionality or relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit processing of protocol parts for development\n",
    "PROCESS_PARTS_LIMIT = 2\n",
    "\n",
    "# Enable caching of protocol parts data (not efficient, should only be used for local development with sensible PROCESS_PARTS_LIMIT)\n",
    "PROCESS_PARTS_CACHE = True\n",
    "\n",
    "# Filter the meetings to be processed, these kwargs are passed along to DataFlows filter_rows processor for meetings resource\n",
    "MEETINGS_FILTER_ROWS_KWARGS = {'equals': [{'KnessetNum': 20}]}\n",
    "\n",
    "# Don'e use local data - loads everything from knesset data remote storage\n",
    "# When set to False - also enables caching, so you won't download from remote storage on 2nd run.\n",
    "USE_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_topic_to_set(topic_name):\n",
    "    lines = open(os.path.join(dir_name, topic_name + \".txt\"), 'r').readlines()\n",
    "    return set([line.strip().replace(\"\\ufeff\", \"\") for line in lines])\n",
    "\n",
    "dir_name = \"../topics/lexicons\"        \n",
    "\n",
    "files = os.listdir(dir_name)\n",
    "\n",
    "topics = [file.split('.')[0] for file in files]\n",
    "\n",
    "lexicons = {}\n",
    "for topic_name in topics:\n",
    "    lexicons[topic_name] = read_topic_to_set(topic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/members/mk_individual/datapackage.json\n",
      "using cache data from .cache/members-mk-individual-names\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/people/committees/meeting-attendees/datapackage.json\n"
     ]
    }
   ],
   "source": [
    "from dataflows import filter_rows, cache\n",
    "from datapackage_pipelines_knesset.common_flow import load_knesset_data, load_member_names\n",
    "\n",
    "# Loads a dict containing mapping between knesset member id and the member name\n",
    "member_names = load_member_names(use_data=USE_DATA)\n",
    "\n",
    "# define flow steps for loading the source committee meetings data\n",
    "# the actual loading is done later in the Flow\n",
    "load_steps = (\n",
    "    load_knesset_data('people/committees/meeting-attendees/datapackage.json', USE_DATA),\n",
    "    filter_rows(**MEETINGS_FILTER_ROWS_KWARGS)\n",
    ")\n",
    "\n",
    "if not USE_DATA:\n",
    "    # when loading from URL - enable caching which will skip loading on 2nd run\n",
    "    load_steps = (cache(*load_steps, cache_path='.cache/people-committee-meeting-attendees-knesset-20'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the datapackages which will be loaded\n",
    "\n",
    "Last command's output log should contain urls to datapackage.json files, open them and check the table schema to see the resource metadata and available fields which you can use in the processing functions.\n",
    "\n",
    "Check the [frictionlessdata docs](https://frictionlessdata.io/docs/) for more details about the datapackage file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topics from lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataflows import Flow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "first = True\n",
    "running_index = 0\n",
    "\n",
    "meeting_data_global = None\n",
    "topics_df = None\n",
    "\n",
    "stats = defaultdict(int)\n",
    "member_attended_meetings = defaultdict(int)\n",
    "rows = []\n",
    "\n",
    "def initialize_meeting_data_global(meeting_row):\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    topics_exists = meeting_row['topics'] is not None\n",
    "    topics = \";\".join(meeting_row['topics']) if topics_exists else \"\"\n",
    "\n",
    "    meeting_data_global = {\n",
    "        'KnessetNum': [meeting_row['KnessetNum']],\n",
    "        'CommitteeSessionID': [meeting_row['CommitteeSessionID']],\n",
    "        'Number': [meeting_row['Number']],\n",
    "        'Mks': [';'.join(meeting_row['mks'])] if meeting_row['mks'] is not None else [\"\"],\n",
    "        'Topics': [topics],\n",
    "        'StartDate': [meeting_row['StartDate']],\n",
    "        'CommitteeID': [meeting_row['CommitteeID']]\n",
    "    } \n",
    "    \n",
    "    # Adding topic counts in the 'topics' column \n",
    "    if(topics_exists):\n",
    "        topic_words = topics.split()\n",
    "        topic_words_size_2 = [\" \".join(topic_words[i:i+2]) for i in range(len(topic_words) - 2)]\n",
    "        topic_words_size_3 = [\" \".join(topic_words[i:i+3]) for i in range(len(topic_words) - 3)]\n",
    "      \n",
    "    for topic_name, lexicon in lexicons.items():\n",
    "        if not topics_exists:\n",
    "            meeting_data_global[topic_name + \"_score\"] = [0]\n",
    "        else:\n",
    "            count = lexicon_count(lexicon, topic_words) + lexicon_count(lexicon, topic_words_size_2) + lexicon_count(lexicon, topic_words_size_3)\n",
    "            meeting_data_global[topic_name + \"_score\"] = [count*3]\n",
    "    \n",
    "def word_permutations(word):\n",
    "    clean_word = word.strip()\n",
    "    permutations = [clean_word]\n",
    "    if len(word) > 1 and word.startswith('ה') or word.startswith('ב') or word.startswith('ל'):\n",
    "        permutations.append(word[1:])\n",
    "    return permutations\n",
    "\n",
    "\n",
    "def in_lexicon(word, lexicon):\n",
    "    for p in word_permutations(word):\n",
    "        if p in lexicon:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "            \n",
    "def lexicon_count(lexicon, words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if in_lexicon(word, lexicon):\n",
    "            count += 1\n",
    "    return count     \n",
    "\n",
    "\n",
    "def process_meeting_protocol_part(row):\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    stats['processed parts'] += 1\n",
    "    words = row['body'].split() if row['body'] is not None else []\n",
    "    words_size_2 = [\" \".join(words[i:i+2]) for i in range(len(words) - 2)]\n",
    "    words_size_3 = [\" \".join(words[i:i+3]) for i in range(len(words) - 3)]\n",
    "                    \n",
    "    for topic_name, lexicon in lexicons.items():\n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words)\n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words_size_2)  \n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words_size_3)  \n",
    "            \n",
    "\n",
    "def process_meeting(row):\n",
    "    global topics_df\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    \n",
    "    stats['total meetings'] += 1\n",
    "    if row['attended_mk_individual_ids']:\n",
    "        for mk_id in row['attended_mk_individual_ids']:\n",
    "            member_attended_meetings[mk_id] += 1\n",
    "    parts_filename = row['parts_parsed_filename']\n",
    "    if parts_filename:\n",
    "        initialize_meeting_data_global(row)\n",
    "        if topics_df is None:\n",
    "            topics_df = pd.DataFrame(meeting_data_global)\n",
    "        else:\n",
    "            topics_df = topics_df.append(pd.DataFrame(meeting_data_global), ignore_index=True)\n",
    "        if PROCESS_PARTS_LIMIT and stats['processed parts'] < PROCESS_PARTS_LIMIT:\n",
    "            steps = (load_knesset_data('committees/meeting_protocols_parts/' + parts_filename, USE_DATA),)\n",
    "            if not USE_DATA and PROCESS_PARTS_CACHE:\n",
    "                steps = (cache(*steps, cache_path='.cache/committee-meeting-protocol-parts/' + parts_filename),)\n",
    "            steps += (process_meeting_protocol_part,)\n",
    "            Flow(*steps).process()\n",
    "            running_index += 1\n",
    "\n",
    "process_steps = (process_meeting,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cache data from .cache/people-committee-meeting-attendees-knesset-20\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/committees/meeting_protocols_parts/files/5/6/562716.csv\n",
      "using cache data from .cache/committee-meeting-protocol-parts/files/5/6/562716.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<datapackage.package.Package at 0x7f64354a9518>,\n",
       " {'count_of_rows': 10256,\n",
       "  'bytes': 30129277,\n",
       "  'hash': '9bb63d3b4c724c88df1416113d0fb80c',\n",
       "  'dataset_name': None})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataflows import Flow, dump_to_path\n",
    "\n",
    "Flow(*load_steps, *process_steps, dump_to_path('data/committee-meeting-attendees-parts')).process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KnessetNum</th>\n",
       "      <th>CommitteeSessionID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Mks</th>\n",
       "      <th>Topics</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>CommitteeID</th>\n",
       "      <th>Diplomacy_score</th>\n",
       "      <th>Ecologics_score</th>\n",
       "      <th>Economics_score</th>\n",
       "      <th>Education_score</th>\n",
       "      <th>Health_score</th>\n",
       "      <th>Security_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>562716</td>\n",
       "      <td>1</td>\n",
       "      <td>זאב אלקין – יו\"ר הוועדה המסדרת;ניסן סלומינסקי ...</td>\n",
       "      <td>בחירת יושב-ראש לוועדת הכספים הזמנית</td>\n",
       "      <td>2015-04-01 14:00:00</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>563293</td>\n",
       "      <td>2</td>\n",
       "      <td>ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;אלי...</td>\n",
       "      <td>אישור השקעת המדינה בחברת דואר ישראל בע\"מ בהתאם...</td>\n",
       "      <td>2015-04-16 10:30:00</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>563590</td>\n",
       "      <td>3</td>\n",
       "      <td>ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;אלי...</td>\n",
       "      <td>אישור השקעת המדינה בחברת דואר ישראל בע\"מ בהתאם...</td>\n",
       "      <td>2015-04-16 12:30:00</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>563523</td>\n",
       "      <td>2</td>\n",
       "      <td>זאב אלקין – היו\"ר;מיקי זוהר;נאוה בוקר;יואב בן ...</td>\n",
       "      <td>החלטה בדבר כינוס המליאה בפגרה לצורך מינוי סגני...</td>\n",
       "      <td>2015-04-15 09:45:00</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>562190</td>\n",
       "      <td>1</td>\n",
       "      <td>זאב אלקין – היו\"ר;יריב לוין;דני דנון;רוברט איל...</td>\n",
       "      <td>אישור מועדי פגרת הפסח.;בחירת ועדות זמניות לעני...</td>\n",
       "      <td>2015-03-31 18:30:00</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>564118</td>\n",
       "      <td>4</td>\n",
       "      <td>ניסן סלומינסקי – היו\"ר;יצחק כהן;מיקי לוי;אורי ...</td>\n",
       "      <td>הארכת מועדים לפי חוק מימון מפלגות, התשל\"ג-1973</td>\n",
       "      <td>2015-05-11 13:00:00</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>564120</td>\n",
       "      <td>5</td>\n",
       "      <td>ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;מיק...</td>\n",
       "      <td>אישור מוסדות ציבור לעניין סעיף 46 לפקודת מס הכ...</td>\n",
       "      <td>2015-05-11 13:20:00</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>564217</td>\n",
       "      <td>3</td>\n",
       "      <td>זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...</td>\n",
       "      <td>הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ...</td>\n",
       "      <td>2015-05-11 10:15:00</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>564304</td>\n",
       "      <td>4</td>\n",
       "      <td>זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...</td>\n",
       "      <td>הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ...</td>\n",
       "      <td>2015-05-11 13:50:00</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>564337</td>\n",
       "      <td>6</td>\n",
       "      <td>זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...</td>\n",
       "      <td>הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ...</td>\n",
       "      <td>2015-05-12 00:40:00</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KnessetNum  CommitteeSessionID Number  \\\n",
       "0          20              562716      1   \n",
       "1          20              563293      2   \n",
       "2          20              563590      3   \n",
       "3          20              563523      2   \n",
       "4          20              562190      1   \n",
       "5          20              564118      4   \n",
       "6          20              564120      5   \n",
       "7          20              564217      3   \n",
       "8          20              564304      4   \n",
       "9          20              564337      6   \n",
       "\n",
       "                                                 Mks  \\\n",
       "0  זאב אלקין – יו\"ר הוועדה המסדרת;ניסן סלומינסקי ...   \n",
       "1  ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;אלי...   \n",
       "2  ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;אלי...   \n",
       "3  זאב אלקין – היו\"ר;מיקי זוהר;נאוה בוקר;יואב בן ...   \n",
       "4  זאב אלקין – היו\"ר;יריב לוין;דני דנון;רוברט איל...   \n",
       "5  ניסן סלומינסקי – היו\"ר;יצחק כהן;מיקי לוי;אורי ...   \n",
       "6  ניסן סלומינסקי – היו\"ר;אלי אלאלוף;יצחק כהן;מיק...   \n",
       "7  זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...   \n",
       "8  זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...   \n",
       "9  זאב אלקין – היו\"ר;רוברט אילטוב;נאוה בוקר;דוד ב...   \n",
       "\n",
       "                                              Topics           StartDate  \\\n",
       "0                בחירת יושב-ראש לוועדת הכספים הזמנית 2015-04-01 14:00:00   \n",
       "1  אישור השקעת המדינה בחברת דואר ישראל בע\"מ בהתאם... 2015-04-16 10:30:00   \n",
       "2  אישור השקעת המדינה בחברת דואר ישראל בע\"מ בהתאם... 2015-04-16 12:30:00   \n",
       "3  החלטה בדבר כינוס המליאה בפגרה לצורך מינוי סגני... 2015-04-15 09:45:00   \n",
       "4  אישור מועדי פגרת הפסח.;בחירת ועדות זמניות לעני... 2015-03-31 18:30:00   \n",
       "5     הארכת מועדים לפי חוק מימון מפלגות, התשל\"ג-1973 2015-05-11 13:00:00   \n",
       "6  אישור מוסדות ציבור לעניין סעיף 46 לפקודת מס הכ... 2015-05-11 13:20:00   \n",
       "7  הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ... 2015-05-11 10:15:00   \n",
       "8  הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ... 2015-05-11 13:50:00   \n",
       "9  הצעת חוק-יסוד: הממשלה (תיקון מס' 3 והוראת שעה ... 2015-05-12 00:40:00   \n",
       "\n",
       "   CommitteeID  Diplomacy_score  Ecologics_score  Economics_score  \\\n",
       "0          922                0                0                3   \n",
       "1          922                0                0                0   \n",
       "2          922                0                0                0   \n",
       "3          938                0                0                0   \n",
       "4          938                0                0                3   \n",
       "5          922                0                0                0   \n",
       "6          922                0                0                0   \n",
       "7          938                0                0                0   \n",
       "8          938                0                0                0   \n",
       "9          938                0                0                0   \n",
       "\n",
       "   Education_score  Health_score  Security_score  \n",
       "0                0             0               0  \n",
       "1                0             0               0  \n",
       "2                0             0               0  \n",
       "3                0             0               0  \n",
       "4                0             0               0  \n",
       "5                0             0               0  \n",
       "6                0             0               0  \n",
       "7                0             0               0  \n",
       "8                0             0               0  \n",
       "9                0             0               0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topics_output.csv\", 'w') as f:\n",
    "    f.write(topics_df.to_csv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataflows import Flow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "first = True\n",
    "running_index = 0\n",
    "\n",
    "meeting_data_global = None\n",
    "topics_df = None\n",
    "\n",
    "stats = defaultdict(int)\n",
    "member_attended_meetings = defaultdict(int)\n",
    "rows = []\n",
    "\n",
    "def initialize_meeting_data_global(meeting_row):\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    topics_exists = meeting_row['topics'] is not None\n",
    "    topics = \";\".join(meeting_row['topics']) if topics_exists else \"\"\n",
    "\n",
    "    meeting_data_global = {\n",
    "        'KnessetNum': [meeting_row['KnessetNum']],\n",
    "        'CommitteeSessionID': [meeting_row['CommitteeSessionID']],\n",
    "        'Number': [meeting_row['Number']],\n",
    "        'Mks': [';'.join(meeting_row['mks'])] if meeting_row['mks'] is not None else [\"\"],\n",
    "        'Topics': [topics],\n",
    "        'StartDate': [meeting_row['StartDate']],\n",
    "        'CommitteeID': [meeting_row['CommitteeID']]\n",
    "    } \n",
    "    \n",
    "    # Adding topic counts in the 'topics' column \n",
    "    if(topics_exists):\n",
    "        topic_words = topics.split()\n",
    "        topic_words_size_2 = [\" \".join(topic_words[i:i+2]) for i in range(len(topic_words) - 2)]\n",
    "        topic_words_size_3 = [\" \".join(topic_words[i:i+3]) for i in range(len(topic_words) - 3)]\n",
    "      \n",
    "    for topic_name, lexicon in lexicons.items():\n",
    "        if not topics_exists:\n",
    "            meeting_data_global[topic_name + \"_score\"] = [0]\n",
    "        else:\n",
    "            count = lexicon_count(lexicon, topic_words) + lexicon_count(lexicon, topic_words_size_2) + lexicon_count(lexicon, topic_words_size_3)\n",
    "            meeting_data_global[topic_name + \"_score\"] = [count*3]\n",
    "    \n",
    "def word_permutations(word):\n",
    "    clean_word = word.strip()\n",
    "    permutations = [clean_word]\n",
    "    if len(word) > 1 and word.startswith('ה') or word.startswith('ב') or word.startswith('ל'):\n",
    "        permutations.append(word[1:])\n",
    "    return permutations\n",
    "\n",
    "\n",
    "def in_lexicon(word, lexicon):\n",
    "    for p in word_permutations(word):\n",
    "        if p in lexicon:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "            \n",
    "def lexicon_count(lexicon, words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if in_lexicon(word, lexicon):\n",
    "            count += 1\n",
    "    return count     \n",
    "\n",
    "\n",
    "def process_meeting_protocol_part(row):\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    stats['processed parts'] += 1\n",
    "    words = row['body'].split() if row['body'] is not None else []\n",
    "    words_size_2 = [\" \".join(words[i:i+2]) for i in range(len(words) - 2)]\n",
    "    words_size_3 = [\" \".join(words[i:i+3]) for i in range(len(words) - 3)]\n",
    "                    \n",
    "    for topic_name, lexicon in lexicons.items():\n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words)\n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words_size_2)  \n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words_size_3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate and print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- top attended members --\n",
      "['איתן ברושי', 'מיכאל לוי', 'דוב חנין', 'משה גפני', 'אורי מקלב']\n",
      "\n",
      "\n",
      "-- stats --\n",
      "processed parts: 624\n",
      "total meetings: 9402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import yaml\n",
    "\n",
    "top_attended_member_names = [member_names[mk_id] for mk_id, num_attended in\n",
    "                             deque(sorted(member_attended_meetings.items(), key=lambda kv: kv[1]), maxlen=5)]\n",
    "print('\\n')\n",
    "print('-- top attended members --')\n",
    "print(top_attended_member_names)\n",
    "print('\\n')\n",
    "print('-- stats --')\n",
    "print(yaml.dump(dict(stats), default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get output data\n",
    "\n",
    "Output data is available in the left sidebar under data directory, you can check the datapackage.json and created csv file to explore the data and schema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
