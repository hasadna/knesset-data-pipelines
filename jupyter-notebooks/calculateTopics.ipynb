{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example flow for processing and aggregating stats about committee meeting attendees and protocol parts\n",
    "\n",
    "See the [DataFlows documentation](https://github.com/datahq/dataflows) for more details regarding the Flow object and processing functions.\n",
    "\n",
    "Feel free to modify and commit changes which demonstrate additional functionality or relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit processing of protocol parts for development\n",
    "PROCESS_PARTS_LIMIT = 20\n",
    "\n",
    "# Enable caching of protocol parts data (not efficient, should only be used for local development with sensible PROCESS_PARTS_LIMIT)\n",
    "PROCESS_PARTS_CACHE = True\n",
    "\n",
    "# Filter the meetings to be processed, these kwargs are passed along to DataFlows filter_rows processor for meetings resource\n",
    "MEETINGS_FILTER_ROWS_KWARGS = {'equals': [{'KnessetNum': 20}]}\n",
    "\n",
    "# Don'e use local data - loads everything from knesset data remote storage\n",
    "# When set to False - also enables caching, so you won't download from remote storage on 2nd run.\n",
    "USE_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Diplomacy': {'BDS',\n",
       "  'או\"ם',\n",
       "  'אום',\n",
       "  'ארצות הברית',\n",
       "  'גרמניה',\n",
       "  'דיפלומט',\n",
       "  'דיפלומטים',\n",
       "  'דיפלומטית',\n",
       "  'הודו',\n",
       "  'הולנד',\n",
       "  'משלחות',\n",
       "  'משלחת',\n",
       "  'משרד החוץ',\n",
       "  'צרפת',\n",
       "  'קונסוליה',\n",
       "  'קונסוליות',\n",
       "  'שגריר',\n",
       "  'שגרירה',\n",
       "  'שגרירויות',\n",
       "  'שגרירות',\n",
       "  'שגרירים'},\n",
       " 'Ecologics': {'איכות הסביבה',\n",
       "  'אקולוגיה',\n",
       "  'זיהום',\n",
       "  'למחזר',\n",
       "  'מזהם',\n",
       "  'מזהמות',\n",
       "  'מזהמים',\n",
       "  'מזהמת',\n",
       "  'מחזור',\n",
       "  'מיחזור',\n",
       "  'ממחזר',\n",
       "  'ממחזרות',\n",
       "  'ממחזרים',\n",
       "  'ממחזרת'},\n",
       " 'Economics': {'אוברדראפט',\n",
       "  'אוצר',\n",
       "  'אינפלציה',\n",
       "  'אשראי',\n",
       "  'בנק',\n",
       "  'בנקים',\n",
       "  'דיפלציה',\n",
       "  'דפלציה',\n",
       "  'הלוואה',\n",
       "  'הלוואות',\n",
       "  'כלכלה',\n",
       "  'כלכלית',\n",
       "  'מניה',\n",
       "  'מניות',\n",
       "  'משכורות',\n",
       "  'משכורת',\n",
       "  'משכנתא',\n",
       "  'משכנתאות',\n",
       "  'נדל\"ן',\n",
       "  'נדלן',\n",
       "  'סוציאליזם',\n",
       "  'פנסיה',\n",
       "  'פנסיות',\n",
       "  'קפיטליזם',\n",
       "  'ריבית',\n",
       "  'שכר',\n",
       "  'תוצר לאומי גולמי',\n",
       "  'תוצר מקומי גולמי',\n",
       "  'תל\"ג',\n",
       "  'תלג',\n",
       "  'תמ\"ג',\n",
       "  'תמג'},\n",
       " 'Education': {'בי\"ס',\n",
       "  'בית ספר',\n",
       "  'בתי ספר',\n",
       "  'הוראה',\n",
       "  'יסודי',\n",
       "  'כיתה',\n",
       "  'כיתות',\n",
       "  'מבחן',\n",
       "  'מבחנים',\n",
       "  'מורה',\n",
       "  'מורים',\n",
       "  'שיעור',\n",
       "  'שיעורים',\n",
       "  'תיכון',\n",
       "  'תיכונים',\n",
       "  'תלמיד',\n",
       "  'תלמידה',\n",
       "  'תלמידות',\n",
       "  'תלמידים'},\n",
       " 'Health': {'בית חולים',\n",
       "  'בריאות',\n",
       "  'בתי החולים',\n",
       "  'בתי חולים',\n",
       "  'חולה',\n",
       "  'חולים',\n",
       "  'מרפאה',\n",
       "  'מרפאות',\n",
       "  'ניתוח',\n",
       "  'ניתוחים',\n",
       "  'סל התרופות',\n",
       "  'רופא',\n",
       "  'רופאה',\n",
       "  'רופאות',\n",
       "  'רופאים',\n",
       "  'רפואה',\n",
       "  'תרופה',\n",
       "  'תרופות'},\n",
       " 'Security': {'אזעקה',\n",
       "  'אזעקות',\n",
       "  'בטחון',\n",
       "  'ביטחון',\n",
       "  \"ג'יהאד אסלאמי\",\n",
       "  'גאפ',\n",
       "  'גדוד',\n",
       "  'גדודים',\n",
       "  'דאע\"ש',\n",
       "  'דאעש',\n",
       "  'הגנה',\n",
       "  'הרוגים',\n",
       "  'התקפה',\n",
       "  'חזבאללה',\n",
       "  'חיזבאללה',\n",
       "  'חייל',\n",
       "  'חיילות',\n",
       "  'חיילים',\n",
       "  'חיילת',\n",
       "  'חיל',\n",
       "  'חמאס',\n",
       "  'טיל',\n",
       "  'טילים',\n",
       "  'טנק',\n",
       "  'טנקים',\n",
       "  'כיפת ברזל',\n",
       "  'להגן',\n",
       "  'להתקיף',\n",
       "  'מחבל',\n",
       "  'מחבלת',\n",
       "  'מםקדת',\n",
       "  'מפגע',\n",
       "  'מפגעת',\n",
       "  'מפקד',\n",
       "  'פגועים',\n",
       "  'פיגוע',\n",
       "  'פיגועים',\n",
       "  'פלוגה',\n",
       "  'פלוגות',\n",
       "  'פמצר',\n",
       "  'פצועים',\n",
       "  'פצמ\"ר',\n",
       "  'צבא הגנה לישראל',\n",
       "  'צה\"ל',\n",
       "  'רמטכ\"ל',\n",
       "  'רמטכל',\n",
       "  'שירות חובה',\n",
       "  'שירות קבע'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_topic_to_set(topic_name):\n",
    "    lines = open(os.path.join(dir_name, topic_name + \".txt\"), 'r').readlines()\n",
    "    return set([line.strip().replace(\"\\ufeff\", \"\") for line in lines])\n",
    "\n",
    "dir_name = \"../topics/lexicons\"        \n",
    "\n",
    "files = os.listdir(dir_name)\n",
    "\n",
    "topics = [file.split('.')[0] for file in files]\n",
    "\n",
    "lexicons = {}\n",
    "for topic_name in topics:\n",
    "    lexicons[topic_name] = read_topic_to_set(topic_name)\n",
    "    \n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/members/mk_individual/datapackage.json\n",
      "using cache data from .cache/members-mk-individual-names\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/people/committees/meeting-attendees/datapackage.json\n"
     ]
    }
   ],
   "source": [
    "from dataflows import filter_rows, cache\n",
    "from datapackage_pipelines_knesset.common_flow import load_knesset_data, load_member_names\n",
    "\n",
    "# Loads a dict containing mapping between knesset member id and the member name\n",
    "member_names = load_member_names(use_data=USE_DATA)\n",
    "\n",
    "# define flow steps for loading the source committee meetings data\n",
    "# the actual loading is done later in the Flow\n",
    "load_steps = (\n",
    "    load_knesset_data('people/committees/meeting-attendees/datapackage.json', USE_DATA),\n",
    "    filter_rows(**MEETINGS_FILTER_ROWS_KWARGS)\n",
    ")\n",
    "\n",
    "if not USE_DATA:\n",
    "    # when loading from URL - enable caching which will skip loading on 2nd run\n",
    "    load_steps = (cache(*load_steps, cache_path='.cache/people-committee-meeting-attendees-knesset-20'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the datapackages which will be loaded\n",
    "\n",
    "Last command's output log should contain urls to datapackage.json files, open them and check the table schema to see the resource metadata and available fields which you can use in the processing functions.\n",
    "\n",
    "Check the [frictionlessdata docs](https://frictionlessdata.io/docs/) for more details about the datapackage file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract topics from lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>KnessetNum</th>\n",
       "      <th>CommitteeSessionID</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  KnessetNum  CommitteeSessionID  Number\n",
       "0      0           0                   0       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dictionary = {\n",
    "    'Index': [0],\n",
    "    'KnessetNum': [0],\n",
    "    'CommitteeSessionID': [0],\n",
    "    'Number': [0]\n",
    "}\n",
    "df = pd.DataFrame(dictionary)\n",
    "df\n",
    "#df = pd.DataFrame(columns=['KnessetNum', 'CommitteeSessionID', 'Number'], data=[[0, 0, 0]]),\n",
    "#df.at[0, 'KnessetNum'] = 2\n",
    "#df.at[0, 'CommitteeSessionID'] = 2\n",
    "#df.at[0, 'Number'] = 2\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataflows import Flow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "first = True\n",
    "running_index = 0\n",
    "\n",
    "meeting_data_global = None\n",
    "topics_df = None\n",
    "\n",
    "stats = defaultdict(int)\n",
    "member_attended_meetings = defaultdict(int)\n",
    "rows = []\n",
    "\n",
    "def initialize_meeting_data_global(meeting_row):\n",
    "    global meeting_data_global\n",
    "    meeting_data_global = {\n",
    "        'Index': [running_index],\n",
    "        'KnessetNum': [meeting_row['KnessetNum']],\n",
    "        'CommitteeSessionID': [meeting_row['CommitteeSessionID']],\n",
    "        'Number': [meeting_row['Number']],\n",
    "    }\n",
    "    for topic_name in lexicons:\n",
    "        meeting_data_global[topic_name + \"_score\"] = [0]\n",
    "    \n",
    "def word_permutations(word):\n",
    "    clean_word = word.strip()\n",
    "    permutations = [clean_word]\n",
    "    if len(word) > 1 and word.startswith('ה') or word.startswith('ב') or word.startswith('ל'):\n",
    "        permutations.append(word[1:])\n",
    "    return permutations\n",
    "\n",
    "\n",
    "def in_lexicon(word, lexicon):\n",
    "    for p in word_permutations(word):\n",
    "        if p in lexicon:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "            \n",
    "def lexicon_count(lexicon, words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if in_lexicon(word, lexicon):\n",
    "            count += 1\n",
    "    return count\n",
    "        \n",
    "    \n",
    "def process_meeting_protocol_part(row):\n",
    "    global meeting_data_global\n",
    "    stats['processed parts'] += 1\n",
    "    words = row['body'].split() if row['body'] is not None else []\n",
    "    for topic_name, lexicon in lexicons.items():\n",
    "        meeting_data_global[topic_name + \"_score\"][running_index] += lexicon_count(lexicon, words)  \n",
    "            \n",
    "\n",
    "def process_meeting(row):\n",
    "    global topics_df\n",
    "    global meeting_data_global\n",
    "    global running_index\n",
    "    \n",
    "    stats['total meetings'] += 1\n",
    "    if row['attended_mk_individual_ids']:\n",
    "        for mk_id in row['attended_mk_individual_ids']:\n",
    "            member_attended_meetings[mk_id] += 1\n",
    "    parts_filename = row['parts_parsed_filename']\n",
    "    if parts_filename:\n",
    "        initialize_meeting_data_global(row)\n",
    "        if topics_df is None:\n",
    "            topics_df = pd.DataFrame(meeting_data_global)\n",
    "        else:\n",
    "            topics_df = topics_df.append(pd.DataFrame(meeting_data_global), ignore_index=True)\n",
    "\n",
    "        if PROCESS_PARTS_LIMIT and stats['processed parts'] < PROCESS_PARTS_LIMIT:\n",
    "            steps = (load_knesset_data('committees/meeting_protocols_parts/' + parts_filename, USE_DATA),)\n",
    "            if not USE_DATA and PROCESS_PARTS_CACHE:\n",
    "                steps = (cache(*steps, cache_path='.cache/committee-meeting-protocol-parts/' + parts_filename),)\n",
    "            steps += (process_meeting_protocol_part,)\n",
    "            Flow(*steps).process()\n",
    "\n",
    "process_steps = (process_meeting,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflows import Flow, dump_to_path\n",
    "\n",
    "Flow(*load_steps, *process_steps, dump_to_path('data/committee-meeting-attendees-parts')).process()\n",
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>KnessetNum</th>\n",
       "      <th>CommitteeSessionID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Diplomacy_score</th>\n",
       "      <th>Ecologics_score</th>\n",
       "      <th>Economics_score</th>\n",
       "      <th>Education_score</th>\n",
       "      <th>Health_score</th>\n",
       "      <th>Security_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Index, KnessetNum, CommitteeSessionID, Number, Diplomacy_score, Ecologics_score, Economics_score, Education_score, Health_score, Security_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate and print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- top attended members --\n",
      "['איתן ברושי', 'מיכאל לוי', 'דוב חנין', 'משה גפני', 'אורי מקלב']\n",
      "\n",
      "\n",
      "-- stats --\n",
      "processed parts: 624\n",
      "total meetings: 9402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import yaml\n",
    "\n",
    "top_attended_member_names = [member_names[mk_id] for mk_id, num_attended in\n",
    "                             deque(sorted(member_attended_meetings.items(), key=lambda kv: kv[1]), maxlen=5)]\n",
    "print('\\n')\n",
    "print('-- top attended members --')\n",
    "print(top_attended_member_names)\n",
    "print('\\n')\n",
    "print('-- stats --')\n",
    "print(yaml.dump(dict(stats), default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get output data\n",
    "\n",
    "Output data is available in the left sidebar under data directory, you can check the datapackage.json and created csv file to explore the data and schema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
